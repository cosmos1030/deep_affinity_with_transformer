{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sps = torch.load(\"data/train_sps.ids76.pt\")\n",
    "train_smile = torch.load(\"data/train_smile.ids68.pt\")\n",
    "train_log_ic50 = torch.load(\"data/train_ic50_log.pt\")\n",
    "\n",
    "test_sps = torch.load(\"data/test_sps.ids76.pt\")\n",
    "test_smile = torch.load(\"data/test_smile.ids68.pt\")\n",
    "test_log_ic50 = torch.load(\"data/test_ic50_log.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, position, d_model):\n",
    "        super().__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model).to(device)\n",
    "    \n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1/ torch.pow(10000, (2 * (i//2)) / d_model)\n",
    "        return position * angles\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position = torch.arange(position, device=device).unsqueeze(1),\n",
    "            i = torch.arange(d_model, device=device).unsqueeze(0),\n",
    "            d_model = d_model\n",
    "        )\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "        angle_rads = torch.zeros_like(angle_rads)\n",
    "        angle_rads[:, 0::2] = sines\n",
    "        angle_rads[:, 1::2] = cosines\n",
    "        pos_encoding = angle_rads.unsqueeze(0)\n",
    "\n",
    "        return pos_encoding\n",
    "    def forward(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :inputs.shape[1],:]\n",
    "    \n",
    "\n",
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    matmul_qk = torch.matmul(query, key.transpose(-2,-1))\n",
    "\n",
    "    depth = query.size(-1)\n",
    "    logits = matmul_qk / torch.sqrt(torch.tensor(depth, dtype=torch.float32))\n",
    "\n",
    "    if mask is not None:\n",
    "        print(\"mask shape\")\n",
    "        print(mask.shape)\n",
    "        print(\"logits shape\")\n",
    "        print(logits.shape)\n",
    "        logits += (mask * -1e9)\n",
    "    \n",
    "    attention_weights = F.softmax(logits, dim=-1)\n",
    "\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "    return output, attention_weights\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = nn.Linear(d_model, d_model)\n",
    "        self.key_dense = nn.Linear(d_model, d_model)\n",
    "        self.value_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        return x.permute(0,2,1,3)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.shape[0]\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = scaled_attention.permute(0,2,1,3)\n",
    "        \n",
    "        concat_attention = scaled_attention.contiguous().view(batch_size, -1, self.d_model)\n",
    "\n",
    "        outputs = self.dense(concat_attention)\n",
    "        return outputs\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.multi_head_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        self.dense1 = nn.Linear(d_model, dff)\n",
    "        self.dense2 = nn.Linear(dff, d_model)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "    def forward(self, x, padding_mask):\n",
    "        attn_output = self.multi_head_attention(x,x,x,padding_mask)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.norm1(x+attn_output)\n",
    "        \n",
    "        ffn_output = F.relu(self.dense1(out1))\n",
    "        ffn_output = self.dense2(ffn_output)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.norm2(out1 + ffn_output)\n",
    "        return out2\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_length, num_layers, dff, d_model, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(seq_length, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.enc_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, dff, dropout) for _ in range(num_layers)])\n",
    "        \n",
    "    def forward(self, x, padding_mask):\n",
    "        x = self.embedding(x)\n",
    "        x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, padding_mask)\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout):\n",
    "        super().__init__()\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        self.dense1 = nn.Linear(d_model, dff)\n",
    "        self.dense2 = nn.Linear(dff, d_model)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.norm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "    \n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        attn1 = self.mha1(x,x,x,look_ahead_mask)\n",
    "        attn1 = self.norm1(attn1 + x)\n",
    "\n",
    "        attn2 = self.mha2(attn1, enc_output, enc_output, padding_mask)\n",
    "        attn2 = self.dropout1(attn2)\n",
    "        attn2 = self.norm2(attn2 + attn1)\n",
    "\n",
    "        ffn_output = F.relu(self.dense1(attn2))\n",
    "        ffn_output = self.dense2(ffn_output)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out = self.norm3(ffn_output + attn2)\n",
    "        return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_length, num_layers, dff, d_model, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(seq_length, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, dff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "    def forward(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= torch.sqrt(torch.tensor(self.d_model, dtype=torch.float))\n",
    "        x += self.pos_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, protein_vocab_size, compound_vocab_size, protein_seq_length, compound_seq_length, num_layers, dff, protein_embedding_dim, compound_embedding_dim, num_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(protein_vocab_size, protein_seq_length, num_layers, dff, protein_embedding_dim, num_heads, dropout)\n",
    "        self.layer1 = nn.Linear(protein_embedding_dim, compound_embedding_dim)  # 인코더와 디코더의 임베딩 차원 다른 문제 해결\n",
    "        self.decoder = Decoder(compound_vocab_size, compound_seq_length, num_layers, dff, compound_embedding_dim, num_heads, dropout)\n",
    "        self.final_layer = nn.Linear(compound_embedding_dim, 1)  # 최종적으로 IC50 값을 예측하기 위한 레이어\n",
    "\n",
    "    def forward(self, inp, tar, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "        inter_output1 = self.layer1(enc_output)\n",
    "        dec_output = self.decoder(tar, inter_output1, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        # 디코더 출력에서 시퀀스 길이에 대해 평균을 내어 (batch_size, compound_embedding_dim) 모양을 얻습니다.\n",
    "        pooled_output = torch.mean(dec_output, dim=1)\n",
    "\n",
    "        # 평균 풀링된 출력을 최종 레이어에 통과시켜 IC50 값을 예측합니다.\n",
    "        final_output = self.final_layer(pooled_output)  # (batch_size, 1) 모양의 출력\n",
    "        return final_output\n",
    "\n",
    "\n",
    "def create_padding_mask(x):\n",
    "    # x와 0이 같은지 비교하여 마스크 생성 (x가 0이면 True, 아니면 False)\n",
    "    mask = torch.eq(x, 0).float()\n",
    "    # (batch_size, 1, 1, key의 문장 길이) 형태로 차원 변경\n",
    "    return mask.unsqueeze(1).unsqueeze(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(76, 256)\n",
       "    (pos_encoding): PositionalEncoding()\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (enc_layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (dense1): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (dense2): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(68, 256)\n",
       "    (pos_encoding): PositionalEncoding()\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (dec_layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (query_dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (key_dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (value_dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (dense1): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (dense2): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "        (norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_layer): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "protein_vocab_size = 76 # 토큰 어휘집의 어휘 개수\n",
    "compound_vocab_size = 68 # 토큰 어휘집의 어휘 개수\n",
    "num_layers = 1 # 인코더, 디코더 layer 수\n",
    "dff = 128\n",
    "num_heads = 2\n",
    "dropout = 0\n",
    "protein_seq_length = 152 # 한 문장의 토큰 수\n",
    "compound_seq_length = 100 # 한 문장의 토큰 수\n",
    "protein_embedding_dim = 256\n",
    "compound_embedding_dim = 256\n",
    "batch_size = 64\n",
    "\n",
    "transformer_model = Transformer(protein_vocab_size, compound_vocab_size, protein_seq_length, compound_seq_length, num_layers, dff, protein_embedding_dim, compound_embedding_dim, num_heads, dropout).to(device)\n",
    "\n",
    "# Load the pretrained weights as tensors\n",
    "protein_embedding_weights = torch.load('pretrain/pretrained_protein_model.pth')['embedding.weight']\n",
    "compound_embedding_weights = torch.load('pretrain/pretrained_compound_model.pth')['embedding.weight']\n",
    "\n",
    "# Directly assign the pretrained weights to the embedding layers\n",
    "transformer_model.encoder.embedding.data = protein_embedding_weights\n",
    "transformer_model.decoder.embedding.data = compound_embedding_weights\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(transformer_model.parameters(), lr=0.0001)\n",
    "\n",
    "transformer_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([263583, 152])\n",
      "torch.Size([263583, 100])\n",
      "torch.Size([263583, 1])\n"
     ]
    }
   ],
   "source": [
    "print(train_sps.shape)\n",
    "print(train_smile.shape)\n",
    "print(train_log_ic50.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/4119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 6/4119 [00:00<02:29, 27.47it/s, avg_loss=41.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 12/4119 [00:00<02:25, 28.15it/s, avg_loss=34.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 18/4119 [00:00<02:31, 27.06it/s, avg_loss=28]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|          | 24/4119 [00:00<02:29, 27.37it/s, avg_loss=22.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|          | 30/4119 [00:01<02:30, 27.20it/s, avg_loss=18.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|          | 36/4119 [00:01<02:31, 26.94it/s, avg_loss=16]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|          | 42/4119 [00:01<02:27, 27.56it/s, avg_loss=14.1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|          | 48/4119 [00:01<02:27, 27.54it/s, avg_loss=12.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|▏         | 54/4119 [00:01<02:28, 27.38it/s, avg_loss=11.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|▏         | 60/4119 [00:02<02:29, 27.14it/s, avg_loss=10.6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   2%|▏         | 66/4119 [00:02<02:27, 27.53it/s, avg_loss=9.8] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   2%|▏         | 72/4119 [00:02<02:32, 26.57it/s, avg_loss=9.18]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   2%|▏         | 79/4119 [00:02<02:15, 29.72it/s, avg_loss=8.56]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   2%|▏         | 85/4119 [00:03<02:20, 28.66it/s, avg_loss=8.11]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   2%|▏         | 91/4119 [00:03<02:23, 28.02it/s, avg_loss=7.7] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   2%|▏         | 97/4119 [00:03<02:25, 27.62it/s, avg_loss=7.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   3%|▎         | 103/4119 [00:03<02:27, 27.29it/s, avg_loss=7.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   3%|▎         | 109/4119 [00:03<02:25, 27.50it/s, avg_loss=6.78]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   3%|▎         | 113/4119 [00:04<02:25, 27.50it/s, avg_loss=6.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 152, 152])\n",
      "mask shape\n",
      "torch.Size([64, 1, 1, 152])\n",
      "logits shape\n",
      "torch.Size([64, 2, 100, 152])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# tqdm을 사용하여 진행 상황 막대 표시\u001b[39;00m\n\u001b[1;32m     20\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(data_loader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(data_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (sps, smile, log_ic50) \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[1;32m     23\u001b[0m     sps \u001b[38;5;241m=\u001b[39m sps\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     24\u001b[0m     smile \u001b[38;5;241m=\u001b[39m smile\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda117/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda117/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda117/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda117/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda117/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda117/lib/python3.10/site-packages/torch/utils/data/dataset.py:193\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cuda117/lib/python3.10/site-packages/torch/utils/data/dataset.py:193\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# DataLoader 설정\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "\n",
    "dataset = TensorDataset(train_sps, train_smile, train_log_ic50)  # 종속 변수를 포함합니다.\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=True)\n",
    "\n",
    "# 에폭 수 설정\n",
    "num_epochs = 10\n",
    "\n",
    "# 훈련 시작\n",
    "for epoch in range(num_epochs):\n",
    "    transformer_model.to(device)\n",
    "    transformer_model.train()  # 모델을 훈련 모드로 설정\n",
    "    total_loss = 0.0  # 에폭별 총 손실을 추적\n",
    "    \n",
    "    # tqdm을 사용하여 진행 상황 막대 표시\n",
    "    progress_bar = tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for batch_idx, (sps, smile, log_ic50) in progress_bar:\n",
    "        sps = sps.to(device)\n",
    "        smile = smile.to(device)\n",
    "        log_ic50 = log_ic50.to(device)\n",
    "\n",
    "        sps_mask = create_padding_mask(sps)\n",
    "        smile_mask = create_padding_mask(sps)\n",
    "\n",
    "        optimizer.zero_grad()  # 그라디언트 초기화\n",
    "        \n",
    "        output = transformer_model(sps, smile, sps_mask, None, smile_mask) # drug sequence에서 look ahead mask는 필요가 없음\n",
    "        \n",
    "        loss = criterion(output.squeeze(), log_ic50.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 진행률 막대에 현재 평균 손실 표시\n",
    "        progress_bar.set_postfix({'avg_loss': total_loss / (batch_idx + 1)})\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Average Loss: 1.4736469710761064\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TensorDataset(test_sps, test_smile, test_log_ic50)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "transformer_model.eval()\n",
    "\n",
    "total_loss = 0.0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sps, smile, log_ic50 in test_loader:\n",
    "        sps = sps.to(device)\n",
    "        smile = smile.to(device)\n",
    "        log_ic50 = log_ic50.to(device)\n",
    "\n",
    "        sps_mask = create_padding_mask(sps)\n",
    "        smile_mask = create_padding_mask(sps)\n",
    "\n",
    "        output = transformer_model(sps, smile, sps_mask, None, smile_mask)\n",
    "        loss = criterion(output.squeeze(), log_ic50.float())\n",
    "\n",
    "        total_loss += loss.item() * sps.size(0)\n",
    "        total_samples += sps.size(0)\n",
    "\n",
    "avg_loss = total_loss / total_samples\n",
    "\n",
    "print(f\"Test Average Loss: {avg_loss**0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda117",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
