{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sps = torch.load(\"../data/train_sps.ids76.pt\")\n",
    "train_smile = torch.load(\"../data/train_smile.ids68.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)  # Output layer to predict the next token\n",
    "\n",
    "    def forward(self, sequence_data):\n",
    "        embedded = self.embedding(sequence_data)\n",
    "        rnn_out, _ = self.rnn(embedded)\n",
    "        output = self.fc(rnn_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "protein_vocab_size = 76 # 토큰 어휘집의 어휘 개수\n",
    "compound_vocab_size = 68 # 토큰 어휘집의 어휘 개수\n",
    "protein_seq_length = 152 # 한 문장의 토큰 수\n",
    "compound_seq_length = 100 # 한 문장의 토큰 수\n",
    "embedding_dim = 256\n",
    "hidden_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PretrainRNNModel(\n",
       "  (embedding): Embedding(76, 256)\n",
       "  (rnn): GRU(256, 128, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=76, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps_model = PretrainRNNModel(protein_vocab_size, embedding_dim, hidden_dim)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(sps_model.parameters(), lr=0.001)\n",
    "\n",
    "sps_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_model(model, device, data_loader, optimizer, criterion, num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        progress_bar = tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch_idx, (seq_data, targets) in progress_bar:\n",
    "            seq_data, targets = seq_data.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(seq_data)\n",
    "            loss = criterion(output.transpose(1, 2), targets)  # Adjust dimensions as needed for CrossEntropyLoss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'avg_loss': total_loss / (batch_idx + 1)})\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "protein_vocab_size = 76  # Adjust based on your dataset\n",
    "embedding_dim = 256\n",
    "hidden_dim = 128\n",
    "compound_vocab_size = 68  # Adjust based on your dataset\n",
    "\n",
    "pretrain_protein_model = PretrainRNNModel(protein_vocab_size, embedding_dim, hidden_dim)\n",
    "pretrain_compound_model = PretrainRNNModel(compound_vocab_size, embedding_dim, hidden_dim)\n",
    "optimizer = Adam(pretrain_protein_model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for next token prediction tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/4119 [00:00<?, ?it/s]/tmp/ipykernel_2992/846713560.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input_seq, dtype=torch.long), torch.tensor(target_seq, dtype=torch.long)\n",
      "Epoch 1/10: 100%|██████████| 4119/4119 [01:04<00:00, 64.10it/s, avg_loss=0.577] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10, Average Loss: 0.5773089828313801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 4119/4119 [00:58<00:00, 70.03it/s, avg_loss=0.354] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10, Average Loss: 0.354042480078158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 4119/4119 [01:01<00:00, 66.86it/s, avg_loss=0.35]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10, Average Loss: 0.34995898694834626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 4119/4119 [01:05<00:00, 62.47it/s, avg_loss=0.352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10, Average Loss: 0.3518570097550862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 4119/4119 [01:03<00:00, 65.01it/s, avg_loss=0.361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10, Average Loss: 0.3611665142229327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 4119/4119 [01:03<00:00, 64.97it/s, avg_loss=0.378] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10, Average Loss: 0.3783399680917429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 4119/4119 [01:05<00:00, 62.56it/s, avg_loss=0.386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10, Average Loss: 0.3856317714764731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 4119/4119 [01:04<00:00, 64.24it/s, avg_loss=0.384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10, Average Loss: 0.38446381396172435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 4119/4119 [01:04<00:00, 63.87it/s, avg_loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10, Average Loss: 0.39378383127657296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 4119/4119 [01:04<00:00, 63.52it/s, avg_loss=0.424]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10, Average Loss: 0.4238755286253607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size=64\n",
    "shuffle = True\n",
    "\n",
    "class NextTokenPredictionDataset(Dataset):\n",
    "    def __init__(self, sequences, sequence_length):\n",
    "        # sequences should be a list of lists or a 2D tensor where each inner list is a sequence\n",
    "        self.sequences = [seq[:sequence_length + 1] for seq in sequences]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        # Input sequence is all but the last token\n",
    "        input_seq = seq[:-1]\n",
    "        # Target sequence is all but the first token\n",
    "        target_seq = seq[1:]\n",
    "        return torch.tensor(input_seq, dtype=torch.long), torch.tensor(target_seq, dtype=torch.long)\n",
    "\n",
    "# Assuming train_sps is a list of lists or a 2D tensor of your sequence data\n",
    "# and you have defined an appropriate sequence_length\n",
    "pretraining_dataset = NextTokenPredictionDataset(train_sps, sequence_length=100)  # Adjust sequence_length as needed\n",
    "\n",
    "pretraining_data_loader = DataLoader(pretraining_dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=True)\n",
    "\n",
    "pretrain_model(pretrain_protein_model, device, pretraining_data_loader, optimizer, criterion, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "embedding_dim = 256\n",
    "hidden_dim = 128\n",
    "compound_vocab_size = 68  # Adjust based on your dataset\n",
    "\n",
    "pretrain_compound_model = PretrainRNNModel(compound_vocab_size, embedding_dim, hidden_dim)\n",
    "optimizer = Adam(pretrain_compound_model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for next token prediction tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/4119 [00:00<?, ?it/s]/tmp/ipykernel_2992/846713560.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(input_seq, dtype=torch.long), torch.tensor(target_seq, dtype=torch.long)\n",
      "Epoch 1/10: 100%|██████████| 4119/4119 [01:05<00:00, 62.43it/s, avg_loss=0.474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10, Average Loss: 0.47414459942555826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 4119/4119 [00:44<00:00, 91.66it/s, avg_loss=0.393] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10, Average Loss: 0.3928944478989458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 4119/4119 [01:06<00:00, 61.93it/s, avg_loss=0.378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10, Average Loss: 0.37776238061207307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 4119/4119 [01:06<00:00, 61.86it/s, avg_loss=0.37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10, Average Loss: 0.36985174314898756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 4119/4119 [01:04<00:00, 63.66it/s, avg_loss=0.368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10, Average Loss: 0.36753168150069904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 4119/4119 [00:57<00:00, 71.93it/s, avg_loss=0.361] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10, Average Loss: 0.3607235517814976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 4119/4119 [01:04<00:00, 63.47it/s, avg_loss=0.358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10, Average Loss: 0.3580589554037218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 4119/4119 [01:06<00:00, 62.26it/s, avg_loss=0.355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10, Average Loss: 0.355190786285926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 4119/4119 [01:05<00:00, 63.13it/s, avg_loss=0.353] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10, Average Loss: 0.35313728367075464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 4119/4119 [01:05<00:00, 62.71it/s, avg_loss=0.36] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10, Average Loss: 0.3595956486386852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming train_sps is a list of lists or a 2D tensor of your sequence data\n",
    "# and you have defined an appropriate sequence_length\n",
    "pretraining_dataset = NextTokenPredictionDataset(train_smile, sequence_length=100)  # Adjust sequence_length as needed\n",
    "\n",
    "pretraining_data_loader = DataLoader(pretraining_dataset, batch_size=batch_size, shuffle=shuffle, pin_memory=True)\n",
    "\n",
    "pretrain_model(pretrain_compound_model, device, pretraining_data_loader, optimizer, criterion, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pretrain_protein_model.state_dict(), 'pretrained_protein_model.pth')\n",
    "torch.save(pretrain_compound_model.state_dict(), 'pretrained_compound_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[ 0.1055,  1.2616, -1.3919,  ...,  0.3435,  2.3587,  1.6831],\n",
       "                      [-0.2234,  1.3583,  0.8768,  ..., -2.2165,  0.8472,  0.9924],\n",
       "                      [ 0.4026, -1.0388,  1.0159,  ..., -0.3748,  0.9654,  0.9290],\n",
       "                      ...,\n",
       "                      [-2.6123, -0.5088,  1.0939,  ..., -1.2293,  1.2940,  0.0108],\n",
       "                      [ 0.3689, -0.4273, -1.8101,  ...,  0.2532,  0.2451, -0.4428],\n",
       "                      [-0.7244, -0.0718, -1.0373,  ...,  0.4078,  0.9507,  3.3401]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l0',\n",
       "              tensor([[-0.0991,  0.0993,  0.4668,  ...,  0.1583, -0.0726, -0.1771],\n",
       "                      [-0.0750,  0.1386, -0.1966,  ...,  0.2892,  0.1875, -0.1490],\n",
       "                      [ 0.1319,  0.0021,  0.0430,  ...,  0.0715,  0.1804,  0.0706],\n",
       "                      ...,\n",
       "                      [-0.1801,  0.0707, -0.0700,  ...,  0.0426, -0.0005,  0.1849],\n",
       "                      [-0.1064, -0.0945,  0.0924,  ...,  0.0671, -0.1374,  0.0473],\n",
       "                      [ 0.0142,  0.0138,  0.0075,  ..., -0.2218,  0.0390, -0.1739]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l0',\n",
       "              tensor([[ 1.1955e-01,  8.2697e-01, -3.1361e-01,  ..., -9.6614e-02,\n",
       "                        1.4244e-01,  9.8924e-02],\n",
       "                      [ 6.6914e-01,  1.2683e-01,  4.7000e-02,  ...,  6.3819e-01,\n",
       "                       -4.9620e-02, -1.8843e-01],\n",
       "                      [-3.7746e-01,  3.8602e-01,  2.7219e-01,  ...,  9.2625e-02,\n",
       "                        2.2076e-01,  5.6235e-01],\n",
       "                      ...,\n",
       "                      [-8.3198e-02, -4.4151e-01,  8.2561e-04,  ..., -5.6177e-01,\n",
       "                        4.4931e-01,  5.3622e-02],\n",
       "                      [-2.4636e-01, -2.2617e-01, -4.6319e-01,  ...,  1.1586e-01,\n",
       "                        4.7084e-01, -4.0432e-01],\n",
       "                      [ 2.9774e-01, -4.1081e-02, -1.3640e-01,  ..., -1.9969e-01,\n",
       "                        8.0980e-01, -1.0243e-01]], device='cuda:0')),\n",
       "             ('rnn.bias_ih_l0',\n",
       "              tensor([-1.9407e-01,  3.3559e-02,  2.1194e-01, -1.7484e-02,  1.5240e-01,\n",
       "                       3.6148e-02,  2.5035e-01,  2.1569e-02,  1.5585e-01, -4.4291e-03,\n",
       "                       6.9507e-02,  1.5514e-02,  2.5251e-01,  1.4088e-02,  6.9683e-02,\n",
       "                       2.4035e-01,  3.3324e-01, -1.0244e-01, -6.6323e-02, -5.4732e-02,\n",
       "                      -8.1339e-02, -8.6856e-02,  2.2503e-01,  1.3601e-01,  2.6160e-01,\n",
       "                       4.4846e-01, -2.0450e-02,  1.6300e-01, -5.1843e-02,  4.2058e-01,\n",
       "                      -2.6784e-02,  3.2920e-01,  1.1653e-01,  1.8831e-01,  8.3124e-02,\n",
       "                       8.1289e-02,  5.0235e-02,  3.3112e-01,  6.4256e-02,  9.7929e-02,\n",
       "                       1.4119e-01,  7.2944e-03,  1.4374e-01, -2.3437e-01,  1.6282e-01,\n",
       "                      -4.2944e-02,  1.3068e-01, -4.6872e-02,  2.1145e-01, -1.2414e-01,\n",
       "                      -6.8754e-02,  1.9319e-01,  3.0910e-01,  1.9945e-01,  1.6572e-02,\n",
       "                       1.9489e-01,  2.0838e-01,  7.9256e-02,  5.7439e-02,  2.1130e-01,\n",
       "                       1.1345e-01, -3.2649e-02,  1.3367e-01, -1.0296e-01,  6.6872e-02,\n",
       "                       2.0807e-02,  2.7343e-02,  1.1612e-02,  1.2186e-01,  2.1855e-01,\n",
       "                       6.9513e-02,  1.0238e-01, -9.5060e-02,  1.9012e-01,  1.5655e-01,\n",
       "                      -2.7654e-02,  1.1778e-01,  1.3341e-01,  1.5076e-01,  1.6553e-01,\n",
       "                       8.1440e-02,  1.2574e-01,  3.5813e-03,  4.2763e-02,  3.2993e-02,\n",
       "                       1.9736e-01,  2.6436e-02,  3.1306e-03,  8.8950e-02,  7.1878e-02,\n",
       "                      -3.7164e-02, -6.7200e-02,  2.4614e-02,  1.2140e-02,  1.1803e-01,\n",
       "                       1.8097e-01,  1.1495e-01,  6.3625e-02,  1.1395e-01,  2.1233e-01,\n",
       "                       8.2165e-02, -9.1682e-02, -1.1641e-01,  6.2484e-02,  7.8454e-02,\n",
       "                       9.1110e-02,  1.8645e-01,  1.9362e-01,  1.0523e-01, -3.2992e-02,\n",
       "                       3.7224e-02, -1.4726e-02, -5.3831e-02,  1.6680e-01,  8.5827e-02,\n",
       "                       1.7288e-01, -1.9743e-01,  3.2664e-01,  4.4917e-01,  1.1001e-01,\n",
       "                       1.7782e-01, -1.4460e-01,  1.0590e-01,  2.4559e-01,  4.5399e-02,\n",
       "                       2.3560e-01,  3.2294e-01, -9.9757e-02, -7.0101e-04, -6.6540e-02,\n",
       "                      -2.4543e-01, -3.4049e-01, -3.4815e-01, -4.5976e-01, -1.7878e-01,\n",
       "                       4.7451e-02,  6.5621e-03, -7.0229e-05, -4.5142e-01,  9.4770e-02,\n",
       "                      -2.5392e-01,  1.9189e-01, -1.4708e-02, -4.1946e-01, -2.1811e-01,\n",
       "                       3.4938e-02, -5.7583e-02, -4.9970e-01, -4.6145e-02, -2.7276e-01,\n",
       "                      -4.1366e-01,  1.1109e-01, -7.0017e-02, -4.3611e-01, -3.3717e-01,\n",
       "                       1.4961e-02, -5.0301e-02, -7.4602e-01, -3.8819e-01, -3.2929e-01,\n",
       "                       1.1777e-01, -3.3755e-01, -3.2491e-01, -1.0405e-01,  2.1101e-01,\n",
       "                      -5.4885e-01, -3.0010e-01, -5.5243e-01, -3.2136e-01, -1.2444e-01,\n",
       "                      -2.1530e-01,  2.1798e-01, -4.8498e-01, -2.3210e-01, -9.3682e-02,\n",
       "                       1.2960e-01, -3.4171e-01, -1.0226e-01, -5.2104e-02, -2.9423e-01,\n",
       "                      -3.9990e-01,  1.6302e-02, -9.8527e-02, -7.5426e-01, -2.8859e-01,\n",
       "                       2.4687e-01, -1.5757e-01, -2.6255e-01, -1.4649e-01,  1.8758e-01,\n",
       "                       2.0661e-01, -7.2983e-02,  7.6837e-02, -2.3451e-01,  1.7509e-01,\n",
       "                      -6.1449e-01,  6.3773e-02, -3.0004e-01, -3.5515e-01, -2.2140e-02,\n",
       "                       3.0202e-01,  7.7804e-02, -1.3159e-01, -6.8391e-01, -1.9132e-01,\n",
       "                      -1.6137e-01, -4.5850e-01, -1.5132e-01, -3.3088e-01,  8.5217e-02,\n",
       "                      -3.5181e-01, -7.1029e-01, -1.6988e-01,  2.7331e-02, -5.5273e-02,\n",
       "                      -2.7990e-01, -3.6266e-01,  8.7533e-03, -5.4998e-01, -2.8456e-01,\n",
       "                      -9.9814e-03,  1.5177e-01, -2.1051e-01, -7.5435e-01, -1.7041e-02,\n",
       "                       1.1732e-01, -3.1392e-01, -6.1875e-01, -4.8069e-01, -3.5768e-01,\n",
       "                       1.3537e-01, -6.6827e-02, -3.7401e-01, -8.2388e-02, -1.5915e-01,\n",
       "                       1.2789e-01, -4.1374e-01, -1.8998e-01,  1.8419e-01, -1.6850e-01,\n",
       "                      -3.8565e-01,  5.7416e-02, -7.0732e-03, -4.7577e-01, -2.4930e-01,\n",
       "                       1.5135e-01, -2.2764e-01, -1.2572e-01, -9.3173e-02, -2.4066e-01,\n",
       "                      -3.6879e-01, -8.6223e-01, -4.8859e-01, -3.3367e-01, -2.5634e-01,\n",
       "                      -8.4670e-03,  2.1403e-02,  1.6437e-01,  2.1551e-01,  1.4933e-01,\n",
       "                      -1.8548e-01, -3.4777e-02, -9.9293e-02,  8.6713e-02, -3.1246e-02,\n",
       "                      -5.5924e-02,  1.3228e-01,  2.7485e-02,  1.9526e-02,  6.4867e-02,\n",
       "                       1.3454e-01, -5.6355e-02,  9.4216e-02,  1.5529e-01, -2.2750e-01,\n",
       "                      -3.1724e-01, -5.1656e-02,  9.5463e-02, -2.1056e-01, -4.0223e-02,\n",
       "                       9.2337e-02, -1.7205e-01,  1.3627e-01, -5.8719e-02,  1.0559e-01,\n",
       "                       9.2553e-02, -6.6829e-02, -1.7969e-01, -1.7356e-02, -1.4696e-02,\n",
       "                      -1.3321e-01,  5.3046e-02, -1.3242e-02, -1.3928e-01, -1.0346e-01,\n",
       "                       1.2637e-02,  2.0061e-01, -1.0631e-01,  9.1755e-02,  1.5830e-01,\n",
       "                       4.4004e-02, -1.6384e-02,  5.1745e-03, -3.6730e-02,  1.2355e-01,\n",
       "                       2.6243e-02, -1.1587e-03, -2.2246e-02, -1.8645e-01,  3.4557e-02,\n",
       "                      -9.6310e-02, -2.1695e-02, -4.2803e-03, -4.6774e-02, -1.7563e-01,\n",
       "                       1.3261e-02, -1.8991e-01, -6.3042e-02,  7.2904e-02,  6.9268e-02,\n",
       "                      -5.1005e-02, -4.6425e-02, -1.8243e-01, -3.9756e-02, -3.7728e-02,\n",
       "                      -1.8455e-02, -2.3003e-02,  8.2295e-02, -4.4324e-02,  1.7387e-01,\n",
       "                       4.9682e-02,  4.6470e-02,  1.2193e-01,  1.1957e-01,  5.7086e-02,\n",
       "                      -5.8030e-02,  1.0530e-01,  3.6625e-02, -3.2651e-02, -8.3760e-03,\n",
       "                       9.0645e-02,  8.9922e-02, -3.6424e-02, -2.2117e-02, -3.8259e-02,\n",
       "                       4.0274e-02,  4.4239e-03,  2.2673e-01, -1.3289e-02,  4.1006e-02,\n",
       "                       6.1059e-02, -1.5515e-01,  1.9166e-01, -2.1474e-01,  7.3048e-02,\n",
       "                       2.8713e-01, -1.3704e-01, -1.5774e-01, -6.5940e-02,  1.3648e-01,\n",
       "                      -2.0371e-01, -1.6303e-01,  3.5153e-02,  8.5813e-02, -9.9319e-02,\n",
       "                      -1.5536e-01,  7.8160e-02, -1.3050e-01,  7.3936e-02,  4.0649e-02,\n",
       "                       4.8844e-02, -6.8761e-02,  1.1308e-01, -2.1924e-03,  2.0239e-01,\n",
       "                      -1.0129e-03, -1.4225e-01, -1.6859e-01, -1.0424e-01, -1.6816e-01,\n",
       "                       9.2846e-02,  7.2801e-02, -1.6700e-01, -1.3052e-01], device='cuda:0')),\n",
       "             ('rnn.bias_hh_l0',\n",
       "              tensor([-0.1400,  0.0202,  0.1491, -0.0054,  0.1620,  0.1294,  0.2266,  0.0893,\n",
       "                       0.2732,  0.0688,  0.0346,  0.0042,  0.2577, -0.0186,  0.0942,  0.1957,\n",
       "                       0.2693, -0.0260, -0.0344,  0.0417, -0.1251,  0.0637,  0.2832,  0.0893,\n",
       "                       0.2941,  0.4012,  0.0183,  0.0095, -0.0427,  0.3656,  0.0050,  0.3790,\n",
       "                      -0.0203,  0.1168,  0.0610,  0.1207,  0.1462,  0.2737,  0.0671,  0.0514,\n",
       "                       0.1254, -0.0548,  0.0115, -0.1384,  0.2320,  0.0610,  0.0689,  0.0708,\n",
       "                       0.1477, -0.1489, -0.0612,  0.0894,  0.2422,  0.0678, -0.1342,  0.3206,\n",
       "                       0.1344,  0.0216,  0.0969,  0.0870,  0.1910,  0.0155,  0.1893, -0.1012,\n",
       "                       0.0275,  0.0186, -0.1102,  0.0435,  0.2556,  0.1017, -0.0633,  0.1903,\n",
       "                      -0.1905,  0.2496,  0.0754,  0.0405,  0.0960,  0.0194,  0.1604,  0.2828,\n",
       "                       0.1189,  0.0687,  0.0857,  0.1125,  0.0786,  0.1699,  0.1078,  0.1711,\n",
       "                       0.0992,  0.0382,  0.0291,  0.0729,  0.0211, -0.0855,  0.1580,  0.1427,\n",
       "                       0.0854, -0.0275,  0.1315,  0.2990,  0.1568, -0.1143, -0.1155,  0.0833,\n",
       "                       0.1290,  0.0520,  0.1926,  0.0750,  0.0525,  0.0037,  0.0768, -0.0573,\n",
       "                      -0.0872,  0.1729,  0.0647,  0.1053, -0.1188,  0.2599,  0.3229,  0.0139,\n",
       "                       0.1619, -0.0250,  0.0897,  0.1926,  0.0690,  0.2194,  0.1940, -0.0859,\n",
       "                      -0.0337, -0.1719, -0.1838, -0.2538, -0.3845, -0.3353, -0.1139, -0.0821,\n",
       "                      -0.0863, -0.0334, -0.5939,  0.1517, -0.2019,  0.2107,  0.0123, -0.2595,\n",
       "                      -0.3294,  0.0900, -0.1144, -0.4262, -0.1606, -0.2646, -0.2917,  0.1361,\n",
       "                      -0.1899, -0.2933, -0.4037, -0.1168, -0.0156, -0.8159, -0.5409, -0.3560,\n",
       "                       0.2029, -0.2815, -0.2191, -0.0305,  0.1268, -0.4576, -0.2912, -0.5359,\n",
       "                      -0.3117, -0.0636, -0.2906,  0.1446, -0.5902, -0.0949, -0.0605,  0.1502,\n",
       "                      -0.2880, -0.1663, -0.1632, -0.1968, -0.3533, -0.0527, -0.1085, -0.6416,\n",
       "                      -0.3128,  0.2117, -0.0920, -0.2652, -0.1313,  0.0611,  0.1752, -0.1946,\n",
       "                       0.1440, -0.1143,  0.2333, -0.4726, -0.0865, -0.3374, -0.3155, -0.1449,\n",
       "                       0.2977,  0.0767, -0.0253, -0.7525, -0.1898, -0.2515, -0.3551, -0.0987,\n",
       "                      -0.2236,  0.2000, -0.2270, -0.5673, -0.2666,  0.0837, -0.0119, -0.2077,\n",
       "                      -0.3659,  0.0635, -0.5478, -0.4156,  0.1479,  0.2915, -0.2853, -0.6149,\n",
       "                      -0.0684,  0.1558, -0.3474, -0.6418, -0.5979, -0.3247,  0.0972,  0.0126,\n",
       "                      -0.3407, -0.0948, -0.2810,  0.1489, -0.3647, -0.0923,  0.0748, -0.2961,\n",
       "                      -0.4063, -0.0143,  0.1326, -0.3607, -0.1222,  0.0811, -0.2276,  0.0021,\n",
       "                      -0.1308, -0.3645, -0.2224, -0.9269, -0.3872, -0.4940, -0.4174,  0.0572,\n",
       "                       0.0674, -0.3819, -0.0083,  0.4305, -0.0396, -0.1772, -0.0878,  0.0094,\n",
       "                      -0.2855,  0.2816, -0.3299, -0.0685,  0.4087, -0.0555, -0.3089,  0.2164,\n",
       "                       0.2813,  0.0690, -0.1475, -0.1780,  0.0314, -0.0798,  0.4033,  0.2766,\n",
       "                       0.0228,  0.0837, -0.1004, -0.2385, -0.2188, -0.1738, -0.1229,  0.0524,\n",
       "                      -0.2019,  0.4907, -0.0215, -0.0788,  0.3144,  0.3237,  0.1377,  0.3544,\n",
       "                      -0.1036, -0.1022,  0.0550, -0.2906, -0.0779, -0.0799,  0.2560, -0.1892,\n",
       "                       0.0474,  0.2225, -0.0632,  0.1847, -0.0962, -0.2067, -0.0160,  0.5330,\n",
       "                       0.5861, -0.0092,  0.2588,  0.1964,  0.3579,  0.0776,  0.0723,  0.0233,\n",
       "                       0.0961,  0.0530, -0.0658,  0.2868, -0.2660,  0.0699,  0.0755,  0.0448,\n",
       "                      -0.1485, -0.2853, -0.0586,  0.3108,  0.1865,  0.0494,  0.1528, -0.2411,\n",
       "                       0.2431,  0.2245, -0.4865, -0.7895,  0.0237, -0.0939, -0.2067, -0.1629,\n",
       "                      -0.1899,  0.1488,  0.3421, -0.0589, -0.1413, -0.0459, -0.0428,  0.2353,\n",
       "                      -0.0828, -0.1995, -0.0606, -0.0185,  0.7819,  0.1940, -0.1203, -0.0231,\n",
       "                       0.2339, -0.2524, -0.0126,  0.1043, -0.4395,  0.3239,  0.1521, -0.2292,\n",
       "                      -0.2585,  0.3838, -0.1710,  0.1284,  0.0965,  0.0231, -0.3018, -0.1186,\n",
       "                       0.0072, -0.1196, -0.0443, -0.0297,  0.4446, -0.2226, -0.2877,  0.1337],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.weight',\n",
       "              tensor([[ 2.2771e-01, -2.7157e-01,  1.0597e-03,  ..., -4.3841e-01,\n",
       "                        1.7351e-01, -1.3301e-01],\n",
       "                      [-3.3222e-01,  9.4048e-02, -7.5971e-01,  ...,  2.8887e-01,\n",
       "                        4.8050e-01,  4.3585e-01],\n",
       "                      [-3.2327e-01,  9.5414e-02, -7.7535e-01,  ...,  2.8799e-01,\n",
       "                        4.9162e-01,  4.5215e-01],\n",
       "                      ...,\n",
       "                      [-1.1389e-01, -6.3821e-02, -5.2135e-01,  ..., -4.9178e-01,\n",
       "                        7.5658e-01, -4.0287e-01],\n",
       "                      [ 1.1070e-01, -1.0486e-01, -1.8632e-01,  ...,  2.5675e-01,\n",
       "                        2.2410e-01,  1.2283e+00],\n",
       "                      [-4.8124e-01,  9.5532e-01,  8.0856e-03,  ...,  6.7856e-01,\n",
       "                       -2.6041e-01, -2.7132e-01]], device='cuda:0')),\n",
       "             ('fc.bias',\n",
       "              tensor([ 0.2839, -4.8537, -4.8150, -4.8097,  0.2936,  0.0660,  0.4822,  1.0838,\n",
       "                      -0.2436,  0.1300,  0.2071, -0.0644, -0.1632, -0.7298,  0.3680,  1.0861,\n",
       "                       0.3097,  0.2519, -0.2579,  0.9634,  0.8528,  0.6834,  0.5886,  0.2069,\n",
       "                      -0.1332,  0.0814,  0.1918,  0.5060,  0.1957,  0.1237, -0.7450,  0.3765,\n",
       "                      -0.3297, -0.0604, -0.1597,  0.5803, -0.9641,  0.0961,  0.1353, -0.1904,\n",
       "                       0.1807,  0.1756, -1.0160,  0.0632, -0.3557, -0.1242,  0.7072, -0.5392,\n",
       "                       0.1231,  0.5379, -0.6183, -0.8720, -0.8800, -1.1974, -0.1348, -0.3192,\n",
       "                      -0.8187, -0.8600, -1.3979, -0.8287,  0.1957, -0.7581, -1.1182, -0.1228,\n",
       "                      -0.3875, -1.5857, -0.4112, -0.1234, -1.0841, -0.8507, -1.6864, -0.4124,\n",
       "                      -1.6030, -1.1660, -1.7156, -1.7196], device='cuda:0'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_protein_model.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda117",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
